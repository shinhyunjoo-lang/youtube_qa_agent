import os
import json
from typing import Optional
from datetime import datetime
from langchain_community.document_loaders import YoutubeLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.tools import tool
from langchain_core.prompts import PromptTemplate
from langchain_core.messages import HumanMessage
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.documents import Document

try:
    from langchain.chains.summarize import load_summarize_chain
    from langchain.chains import RetrievalQA
except ImportError:
    from langchain_classic.chains.summarize import load_summarize_chain
    from langchain_classic.chains import RetrievalQA

# Global state for agent (will be set by YouTubeAgent instance)
_agent_state = {
    "llm": None,
    "docs": [],
    "vector_store": None,
    "qa_chain": None,
    "search": None,
    "video_context": "",
    "conversation_memory": {}
}

# ============================================================================
# TOOL DEFINITIONS using @tool decorator
# ============================================================================

@tool
def summarize_video(query: str = "") -> str:
    """Summarizes the entire YouTube video content. Use this when user asks for a general summary or overview."""
    if not _agent_state["docs"]:
        return "ë¹„ë””ì˜¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        # Create a Korean-specific summarization prompt
        korean_prompt = PromptTemplate(
            template="ë‹¤ìŒ ë¹„ë””ì˜¤ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. ì£¼ìš” ë‚´ìš©ê³¼ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ í¬í•¨í•´ì„œ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n\n{text}",
            input_variables=["text"]
        )
        
        chain = load_summarize_chain(_agent_state["llm"], chain_type="map_reduce", map_prompt=korean_prompt, combine_prompt=korean_prompt)
        return chain.run(_agent_state["docs"])
    except Exception as e:
        return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

@tool
def generate_titles(query: str = "") -> str:
    """Generates catchy titles for the video. Use when user asks for title suggestions."""
    if not _agent_state["docs"]:
        return "ë¹„ë””ì˜¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    summary = summarize_video.invoke("")
    prompt = PromptTemplate(
        template="ë‹¤ìŒ ë¹„ë””ì˜¤ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ë§¤ë ¥ì ì¸ í•œêµ­ì–´ ì œëª© 5ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:\n\n{summary}",
        input_variables=["summary"]
    )
    try:
        from langchain.chains import LLMChain
    except ImportError:
        from langchain_classic.chains import LLMChain
    chain = LLMChain(llm=_agent_state["llm"], prompt=prompt)
    return chain.run(summary)

@tool
def write_blog_post(query: str = "") -> str:
    """Writes a blog post based on the video content. Use when user asks for a blog post or article."""
    if not _agent_state["docs"]:
        return "ë¹„ë””ì˜¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    summary = summarize_video.invoke("")
    prompt = PromptTemplate(
        template="ë‹¤ìŒ ë¹„ë””ì˜¤ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì„œë¡ , ë³¸ë¡ , ê²°ë¡  êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:\n\n{summary}",
        input_variables=["summary"]
    )
    try:
        from langchain.chains import LLMChain
    except ImportError:
        from langchain_classic.chains import LLMChain
    chain = LLMChain(llm=_agent_state["llm"], prompt=prompt)
    return chain.run(summary)

@tool
def generate_quiz(query: str = "") -> str:
    """Generates a multiple choice quiz based on video content. Use when user asks for a quiz or test."""
    if not _agent_state["docs"]:
        return "ë¹„ë””ì˜¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    summary = summarize_video.invoke("")
    prompt = PromptTemplate(
        template="ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ 5ë¬¸í•­ì˜ ê°ê´€ì‹ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ê° ë¬¸í•­ë§ˆë‹¤ 4ê°œì˜ ì„ íƒì§€ì™€ ì •ë‹µì„ í¬í•¨í•´ì£¼ì„¸ìš”:\n\n{summary}",
        input_variables=["summary"]
    )
    try:
        from langchain.chains import LLMChain
    except ImportError:
        from langchain_classic.chains import LLMChain
    chain = LLMChain(llm=_agent_state["llm"], prompt=prompt)
    return chain.run(summary)

@tool
def extract_key_moments(query: str = "") -> str:
    """Extracts key moments, topics, and takeaways from the video. Use when user asks for highlights or main points."""
    if not _agent_state["docs"]:
        return "ë¹„ë””ì˜¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # Use the full transcript instead of summary for better timestamp extraction
    full_content = _agent_state["docs"][0].page_content if _agent_state["docs"] else ""
    
    prompt = PromptTemplate(
        template="""ë‹¤ìŒ ë¹„ë””ì˜¤ ì „ì²´ ë‚´ìš©ì—ì„œ í•µì‹¬ ìˆœê°„ë“¤ê³¼ ì£¼ìš” ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. 
ê° í•µì‹¬ ìˆœê°„ë§ˆë‹¤ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ "0:30", "1:45", "3:20" í˜•ì‹ìœ¼ë¡œ í¬í•¨í•˜ì—¬ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ë¹„ë””ì˜¤ ë‚´ìš©:
{content}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
**0:00 - ì‹œì‘ ë¶€ë¶„**
- ì£¼ìš” ë‚´ìš© ì„¤ëª…

**1:30 - ì¤‘ê°„ ë¶€ë¶„**  
- ì£¼ìš” ë‚´ìš© ì„¤ëª…

**3:45 - ë§ˆë¬´ë¦¬ ë¶€ë¶„**
- ì£¼ìš” ë‚´ìš© ì„¤ëª…

í•µì‹¬ ìˆœê°„ë“¤:""",
        input_variables=["content"]
    )
    try:
        from langchain.chains import LLMChain
    except ImportError:
        from langchain_classic.chains import LLMChain
    chain = LLMChain(llm=_agent_state["llm"], prompt=prompt)
    return chain.run(full_content[:4000])  # Limit content length for better processing

@tool
def search_web(query: str) -> str:
    """Searches the web for information NOT in the video. Use for current events, speaker background, or external facts. 
    IMPORTANT: Query must include specific entities/names from the video context."""
    if not _agent_state["search"]:
        return "ì›¹ ê²€ìƒ‰ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        # Get video context for better search
        video_context = _agent_state.get("video_context", "")
        conversation_memory = _agent_state.get("conversation_memory", {})
        docs = _agent_state.get("docs", [])
        
        # Extract key terms from video content for better search context
        search_context_terms = []
        
        # Get video title
        if "Video Title: " in video_context:
            title = video_context.split("Video Title: ")[1].split("\n")[0]
            if title and title != "YouTube Video":
                search_context_terms.append(f'"{title}"')
        
        # Add memory context
        if conversation_memory:
            for key, value in conversation_memory.items():
                if key == "channel":
                    search_context_terms.append(f'"{value}"')
                elif key == "speaker":
                    search_context_terms.append(f'"{value}"')
                elif key == "event":
                    search_context_terms.append(f'"{value}"')
        
        # Extract key terms from video content (first 1000 characters)
        if docs and len(docs) > 0:
            content_sample = docs[0].page_content[:1000]
            # Use LLM to extract key terms for search
            key_terms_prompt = f"""ë‹¤ìŒ ë¹„ë””ì˜¤ ë‚´ìš©ì—ì„œ ê²€ìƒ‰ì— ìœ ìš©í•œ í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. 
íšŒì‚¬ëª…, ì œí’ˆëª…, ê¸°ìˆ ëª…, ì¸ë¬¼ëª… ë“±ì„ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë¹„ë””ì˜¤ ë‚´ìš©:
{content_sample}

í‚¤ì›Œë“œ:"""
            
            key_terms_response = _agent_state["llm"].invoke([HumanMessage(content=key_terms_prompt)])
            key_terms = key_terms_response.content.strip()
            if key_terms and len(key_terms) > 5:
                search_context_terms.append(key_terms)
        
        # Create enhanced search query
        if search_context_terms:
            enhanced_query = f"{query} {' '.join(search_context_terms)}"
        else:
            enhanced_query = query
            
        print(f"DEBUG: Original query: {query}")
        print(f"DEBUG: Enhanced search query: {enhanced_query}")
        
        search_result = _agent_state["search"].invoke(enhanced_query)
        
        # Filter and contextualize search result
        filter_prompt = f"""ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ í˜„ì¬ ë¹„ë””ì˜¤ì™€ ê´€ë ¨ëœ ë‚´ìš©ë§Œ ì„ ë³„í•˜ê³  í•œêµ­ì–´ë¡œ ë²ˆì—­/ìš”ì•½í•´ì£¼ì„¸ìš”.

í˜„ì¬ ë¹„ë””ì˜¤ ì •ë³´:
- ì œëª©: {video_context}
- ì‚¬ìš©ì ì œê³µ ì •ë³´: {json.dumps(conversation_memory, ensure_ascii=False)}
- ë¹„ë””ì˜¤ ì£¼ìš” ë‚´ìš©: {content_sample[:500] if docs and len(docs) > 0 else 'ì •ë³´ ì—†ìŒ'}

ê²€ìƒ‰ ê²°ê³¼:
{search_result}

ê´€ë ¨ì„±ì´ ë†’ì€ ë‚´ìš©ë§Œ ì„ ë³„í•˜ì—¬ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. ê´€ë ¨ì„±ì´ ë‚®ì€ ë‚´ìš©ì€ ì œì™¸í•˜ê³ , 
í˜„ì¬ ë¹„ë””ì˜¤ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê´€ëœ ê¸°ì‚¬ë‚˜ ì •ë³´ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”:"""
        
        response = _agent_state["llm"].invoke([HumanMessage(content=filter_prompt)])
        return response.content
        
    except Exception as e:
        return f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"

@tool
def store_memory(user_message: str) -> str:
    """Stores factual information provided by the user about the video (e.g., channel name, speaker name).
    ONLY use when user provides NEW facts as STATEMENTS, NOT for questions."""
    try:
        extraction_prompt = f"""Analyze the following user message and extract any factual information they are providing about the video.
Return ONLY a JSON object with key-value pairs. If no factual information is provided, return {{}}.

Examples:
- "ì´ ë¹„ë””ì˜¤ëŠ” AWS Events ì±„ë„ì— ì˜¬ë¼ì™”ì–´" â†’ {{"channel": "AWS Events"}}
- "ë°œí‘œìëŠ” Johnì´ì•¼" â†’ {{"speaker": "John"}}
- "ì´ê±´ re:Invent 2024 ì„¸ì…˜ì´ì•¼" â†’ {{"event": "re:Invent 2024"}}

User message: {user_message}

Return JSON:"""
        
        response = _agent_state["llm"].invoke([HumanMessage(content=extraction_prompt)])
        content = response.content.strip()
        
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].strip()
        
        extracted_data = json.loads(content)
        
        if extracted_data:
            # 1. ë©”ëª¨ë¦¬ì— ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
            _agent_state["conversation_memory"].update(extracted_data)
            
            # 2. ë²¡í„° ìŠ¤í† ì–´ì—ë„ ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì¶”ê°€
            if _agent_state["vector_store"]:
                memory_docs = []
                for key, value in extracted_data.items():
                    # ìì—°ì–´ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë²¡í„°í™”
                    if key == "channel":
                        doc_content = f"ì´ ë¹„ë””ì˜¤ëŠ” {value} ì±„ë„ì—ì„œ ì œê³µë©ë‹ˆë‹¤."
                    elif key == "speaker":
                        doc_content = f"ì´ ë¹„ë””ì˜¤ì˜ ë°œí‘œìëŠ” {value}ì…ë‹ˆë‹¤."
                    elif key == "event":
                        doc_content = f"ì´ ë¹„ë””ì˜¤ëŠ” {value} ì´ë²¤íŠ¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤."
                    else:
                        doc_content = f"ì´ ë¹„ë””ì˜¤ì˜ {key}ëŠ” {value}ì…ë‹ˆë‹¤."
                    
                    memory_doc = Document(
                        page_content=doc_content,
                        metadata={"type": "memory", "key": key, "value": value}
                    )
                    memory_docs.append(memory_doc)
                
                # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
                _agent_state["vector_store"].add_documents(memory_docs)
                print(f"DEBUG: Added {len(memory_docs)} memory documents to vector store")
            
            stored_keys = ", ".join(extracted_data.keys())
            return f"âœ“ ì •ë³´ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {stored_keys}"
        else:
            return "ì €ì¥í•  ìƒˆë¡œìš´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
            
    except Exception as e:
        return f"ë©”ëª¨ë¦¬ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}"

@tool
def answer_question(question: str) -> str:
    """Answers specific questions about the video content using the transcript. 
    Use for detailed questions about what was said in the video."""
    if not _agent_state["qa_chain"]:
        return "ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ë¥¼ ë‹¤ì‹œ ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    try:
        # Create a Korean-specific QA prompt
        korean_qa_prompt = PromptTemplate(
            template="""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸: {context}

ì§ˆë¬¸: {question}

ë‹µë³€:""",
            input_variables=["context", "question"]
        )
        
        # Update QA chain with Korean prompt
        try:
            from langchain.chains import RetrievalQA
        except ImportError:
            from langchain_classic.chains import RetrievalQA
            
        qa_chain = RetrievalQA.from_chain_type(
            llm=_agent_state["llm"],
            chain_type="stuff",
            retriever=_agent_state["vector_store"].as_retriever(),
            chain_type_kwargs={"prompt": korean_qa_prompt}
        )
        
        return qa_chain.run(question)
    except Exception as e:
        return f"ì§ˆë¬¸ ë‹µë³€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ============================================================================
# YOUTUBE AGENT CLASS
# ============================================================================

class YouTubeAgent:
    def __init__(self, openai_api_key):
        self.openai_api_key = openai_api_key
        os.environ["OPENAI_API_KEY"] = openai_api_key
        self.llm = ChatOpenAI(temperature=0.2, model_name="gpt-4o-mini")
        self.docs = []
        self.vector_store = None
        self.qa_chain = None
        self.search = DuckDuckGoSearchRun()
        self.video_context = ""
        self.conversation_memory = {}
        self.video_id = ""
        
        # Update global state
        _agent_state["llm"] = self.llm
        _agent_state["search"] = self.search
        
        # Create tools mapping for simple routing
        self.tools = {
            "summarize": summarize_video,
            "titles": generate_titles,
            "blog": write_blog_post,
            "quiz": generate_quiz,
            "moments": extract_key_moments,
            "search": search_web,
            "memory": store_memory,
            "answer": answer_question
        }
    
    def save_metadata(self):
        """Save conversation memory and context to JSON file."""
        try:
            db_path = f"db/{self.video_id}"
            os.makedirs(db_path, exist_ok=True)
            
            metadata = {
                "conversation_memory": self.conversation_memory,
                "video_context": self.video_context,
                "timestamp": datetime.now().isoformat(),
                "video_id": self.video_id
            }
            
            metadata_path = f"{db_path}/metadata.json"
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"DEBUG: Saved metadata to {metadata_path}")
        except Exception as e:
            print(f"Warning: Could not save metadata: {e}")
    
    def load_metadata(self):
        """Load conversation memory and context from JSON file."""
        try:
            metadata_path = f"db/{self.video_id}/metadata.json"
            if os.path.exists(metadata_path):
                with open(metadata_path, "r", encoding="utf-8") as f:
                    metadata = json.load(f)
                
                self.conversation_memory = metadata.get("conversation_memory", {})
                saved_context = metadata.get("video_context", "")
                
                # ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ì™€ ë³‘í•©
                if saved_context and saved_context != self.video_context:
                    self.video_context = saved_context
                
                print(f"DEBUG: Loaded metadata from {metadata_path}")
                print(f"DEBUG: Loaded conversation memory: {self.conversation_memory}")
                
                # ê¸€ë¡œë²Œ ìƒíƒœ ì—…ë°ì´íŠ¸
                _agent_state["conversation_memory"] = self.conversation_memory
                _agent_state["video_context"] = self.video_context
                
                return True
        except Exception as e:
            print(f"Warning: Could not load metadata: {e}")
        
        return False
    
    def add_context_to_vector_store(self, summary):
        """Add context summary to vector store for semantic search."""
        if self.vector_store and summary:
            try:
                context_doc = Document(
                    page_content=f"ë¹„ë””ì˜¤ ìš”ì•½: {summary}",
                    metadata={"type": "context_summary"}
                )
                self.vector_store.add_documents([context_doc])
                print("DEBUG: Added context summary to vector store")
            except Exception as e:
                print(f"Warning: Could not add context to vector store: {e}")
    
    def load_video(self, url):
        """Loads the video transcript."""
        try:
            self.docs = []
            self.vector_store = None
            self.qa_chain = None
            self.video_context = ""

            loader = YoutubeLoader.from_youtube_url(url, add_video_info=False, language=["en", "en-US", "ko"])
            self.docs = loader.load()
            
            if not self.docs:
                return "ì˜¤ë¥˜: ì´ ë¹„ë””ì˜¤ì˜ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜ì–´ ë˜ëŠ” í•œêµ­ì–´ ìë§‰ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                
            title = self.docs[0].metadata.get('title', 'YouTube Video')
            self.docs[0].metadata['title'] = title
            self.video_context = f"Video Title: {title}"
            
            # Extract video ID
            if "v=" in url:
                self.video_id = url.split("v=")[1].split("&")[0]
            elif "youtu.be/" in url:
                self.video_id = url.split("youtu.be/")[1].split("?")[0]
            else:
                import hashlib
                self.video_id = hashlib.md5(url.encode()).hexdigest()[:12]
            
            # Update global state
            _agent_state["docs"] = self.docs
            _agent_state["video_context"] = self.video_context
                
            return f"ë¹„ë””ì˜¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {title}"
        except Exception as e:
            return f"ë¹„ë””ì˜¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def create_vector_store(self):
        """Creates a FAISS vector store, using local persistence."""
        if not self.docs:
            return "ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¹„ë””ì˜¤ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        db_path = f"db/{self.video_id}"
        vector_store_loaded = False
        
        # 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ (JSON)
        metadata_loaded = self.load_metadata()
        
        if os.path.exists(db_path):
            try:
                embeddings = OpenAIEmbeddings()
                self.vector_store = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
                print(f"DEBUG: Loaded existing vector store from {db_path}")
                vector_store_loaded = True
            except Exception as e:
                print(f"Warning: Could not load local index: {e}. Recreating.")
        
        if not self.vector_store:
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
            split_docs = text_splitter.split_documents(self.docs)
            
            embeddings = OpenAIEmbeddings()
            self.vector_store = FAISS.from_documents(split_docs, embeddings)
            self.vector_store.save_local(db_path)
            print(f"DEBUG: Saved new vector store to {db_path}")
        
        # Create Korean QA chain
        korean_qa_prompt = PromptTemplate(
            template="""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸: {context}

ì§ˆë¬¸: {question}

ë‹µë³€:""",
            input_variables=["context", "question"]
        )
        
        try:
            from langchain.chains import RetrievalQA
        except ImportError:
            from langchain_classic.chains import RetrievalQA
            
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vector_store.as_retriever(),
            chain_type_kwargs={"prompt": korean_qa_prompt}
        )
        
        # 2. Generate and add context summary to vector store
        if "Summary:" not in self.video_context:
            try:
                brief_content = self.docs[0].page_content[:3000]
                summary_prompt = f"ë‹¤ìŒ ë¹„ë””ì˜¤ ë‚´ìš©ì„ 1-2ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{brief_content}"
                context_summary = self.llm.invoke([HumanMessage(content=summary_prompt)]).content
                self.video_context += f"\nSummary: {context_summary}"
                
                # Add context summary to vector store for semantic search
                self.add_context_to_vector_store(context_summary)
                print(f"DEBUG: Generated context summary")
            except Exception as e:
                print(f"Warning: Could not generate context summary: {e}")
        
        # 3. Add existing conversation memory to vector store (if loaded from JSON)
        if metadata_loaded and self.conversation_memory:
            try:
                memory_docs = []
                for key, value in self.conversation_memory.items():
                    if key == "channel":
                        doc_content = f"ì´ ë¹„ë””ì˜¤ëŠ” {value} ì±„ë„ì—ì„œ ì œê³µë©ë‹ˆë‹¤."
                    elif key == "speaker":
                        doc_content = f"ì´ ë¹„ë””ì˜¤ì˜ ë°œí‘œìëŠ” {value}ì…ë‹ˆë‹¤."
                    elif key == "event":
                        doc_content = f"ì´ ë¹„ë””ì˜¤ëŠ” {value} ì´ë²¤íŠ¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤."
                    else:
                        doc_content = f"ì´ ë¹„ë””ì˜¤ì˜ {key}ëŠ” {value}ì…ë‹ˆë‹¤."
                    
                    memory_doc = Document(
                        page_content=doc_content,
                        metadata={"type": "memory", "key": key, "value": value}
                    )
                    memory_docs.append(memory_doc)
                
                if memory_docs:
                    self.vector_store.add_documents(memory_docs)
                    print(f"DEBUG: Added {len(memory_docs)} existing memory documents to vector store")
            except Exception as e:
                print(f"Warning: Could not add existing memory to vector store: {e}")
        
        # Update global state
        _agent_state["vector_store"] = self.vector_store
        _agent_state["qa_chain"] = self.qa_chain
        _agent_state["video_context"] = self.video_context
        _agent_state["conversation_memory"] = self.conversation_memory
        
        # 4. Save metadata (JSON)
        self.save_metadata()
        
        # Return different messages based on whether vector store was loaded or created
        if vector_store_loaded:
            return "ğŸ“‚ ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤."
        else:
            return "ğŸ”§ ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤."

    def run(self, query):
        """Simple routing-based agent without complex agent framework."""
        if not self.docs:
            return "ë¨¼ì € ë¹„ë””ì˜¤ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        # Pre-check: answer from memory if applicable
        if self.conversation_memory and any(keyword in query.lower() for keyword in ['ë­', 'ë¬´ì—‡', 'ì–´ë–¤', 'ëˆ„êµ¬', 'ì–´ë””', 'ì–¸ì œ', 'what', 'who', 'which', 'where', 'when', 'ì±„ë„']):
            try:
                memory_check_prompt = f"""User has stored the following information:
{json.dumps(self.conversation_memory, ensure_ascii=False, indent=2)}

User question: {query}

If the question is asking about information that exists in the stored data above, answer it directly and concisely in Korean.
If the information is NOT in the stored data, respond with "NOT_FOUND".

Answer:"""
                
                response = self.llm.invoke([HumanMessage(content=memory_check_prompt)])
                answer = response.content.strip()
                
                if answer != "NOT_FOUND" and "NOT_FOUND" not in answer:
                    return f"ğŸ’¾ ì €ì¥ëœ ì •ë³´: {answer}"
            except Exception as e:
                print(f"Memory check error: {e}")
        
        # Update global state before processing
        _agent_state["conversation_memory"] = self.conversation_memory
        
        # Check if user is providing information (statements, not questions)
        if not any(q_word in query for q_word in ['?', 'ë­', 'ë¬´ì—‡', 'ì–´ë””', 'ëˆ„êµ¬', 'ì–¸ì œ', 'ì–´ë–»ê²Œ', 'what', 'who', 'where', 'when', 'how']):
            # This might be a statement providing information
            try:
                result = store_memory.invoke(query)
                if "ì •ë³´ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤" in result:
                    # Update local memory as well
                    extraction_prompt = f"""Analyze the following user message and extract any factual information they are providing about the video.
Return ONLY a JSON object with key-value pairs. If no factual information is provided, return {{}}.

Examples:
- "ì´ ë¹„ë””ì˜¤ëŠ” AWS Events ì±„ë„ì— ì˜¬ë¼ì™”ì–´" â†’ {{"channel": "AWS Events"}}
- "ë°œí‘œìëŠ” Johnì´ì•¼" â†’ {{"speaker": "John"}}
- "ì´ê±´ re:Invent 2024 ì„¸ì…˜ì´ì•¼" â†’ {{"event": "re:Invent 2024"}}

User message: {query}

Return JSON:"""
                    
                    response = self.llm.invoke([HumanMessage(content=extraction_prompt)])
                    content = response.content.strip()
                    
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0].strip()
                    elif "```" in content:
                        content = content.split("```")[1].strip()
                    
                    try:
                        extracted_data = json.loads(content)
                        if extracted_data:
                            self.conversation_memory.update(extracted_data)
                    except:
                        pass
                    
                    return result
            except Exception as e:
                print(f"Memory storage error: {e}")
        
        # Simple routing logic
        query_lower = query.lower()
        
        # Check for specific tool requests
        if any(word in query_lower for word in ['ìš”ì•½', 'summary', 'summarize']):
            return summarize_video.invoke("")
        elif any(word in query_lower for word in ['ì œëª©', 'title', 'titles']):
            return generate_titles.invoke("")
        elif any(word in query_lower for word in ['ë¸”ë¡œê·¸', 'blog', 'post']):
            return write_blog_post.invoke("")
        elif any(word in query_lower for word in ['í€´ì¦ˆ', 'quiz', 'test']):
            return generate_quiz.invoke("")
        elif any(word in query_lower for word in ['í•µì‹¬', 'ì¤‘ìš”', 'key', 'moments', 'highlights']):
            return extract_key_moments.invoke("")
        elif any(word in query_lower for word in ['ê²€ìƒ‰', 'search', 'ì°¾ì•„', 'ê¸°ì‚¬', 'ë‰´ìŠ¤', 'ê´€ë ¨', 'ì¶œì²˜']):
            # Don't modify the original query, just use it as is for search
            print(f"DEBUG: Search triggered by query: {query}")
            
            # If the query is asking for articles or sources, create a better search query
            if any(word in query_lower for word in ['ê¸°ì‚¬', 'ë‰´ìŠ¤', 'ê´€ë ¨', 'ì¶œì²˜']):
                # Use the original query for search
                search_query = query
            else:
                # Extract search terms from query and enhance with video context
                search_query = query.replace('ê²€ìƒ‰', '').replace('ì°¾ì•„', '').replace('search', '').strip()
                
                # If no specific search terms after cleaning, use video context
                if not search_query or len(search_query) < 3:
                    if self.conversation_memory:
                        # Use stored information for search
                        search_terms = []
                        for key, value in self.conversation_memory.items():
                            search_terms.append(str(value))
                        search_query = " ".join(search_terms) + " ê´€ë ¨ ê¸°ì‚¬"
                    else:
                        # Use video title
                        title = self.docs[0].metadata.get('title', '') if self.docs else ''
                        search_query = f"{title} ê´€ë ¨ ê¸°ì‚¬" if title else "ê²€ìƒ‰í•  ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”."
            
            if search_query and search_query != "ê²€ìƒ‰í•  ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.":
                result = search_web.invoke(search_query)
                # Save metadata after any interaction
                self.save_metadata()
                return result
            else:
                return "ê²€ìƒ‰í•  ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”."
        else:
            # Default to answering questions about the video
            result = answer_question.invoke(query)
            # Save metadata after any interaction
            self.save_metadata()
            return result
